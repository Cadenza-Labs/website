---
slug: "/about"
title: ""
---

# Team

## Walter Laurito
[LinkedIn](https://www.linkedin.com/in/walter-laurito-951565144/)

Walter was in the MATS Winter 2023 Cohort under the mentorship of John Wentworth. At Cadenza Labs, he splits his time between being a team lead and research. With other collaborators, his team created an [open-source library](https://github.com/EleutherAI/elk), where Walter is a main contributor. As part of [ASET](https://www.linkedin.com/posts/), he implemented benchmarks for the UK AI Security Institute and supervised others in their implementation. Before starting his PhD in ML, Walter was working as software engineer for a couple of years after graduating in CS.

## Sharan Maiya
[LinkedIn](https://www.linkedin.com/in/sharanmaiya?originalSubdomain=uk)

Sharan first joined Cadenza Labs to work with Walter on Cluster-Normalization for Unsupervised Probing. He is a first-year PhD student at the Language Technology Lab at the University of Cambridge, where he works on interpretability and evals. Additionally, he is a MATS scholar under Evan Hubinger. Sharan has a background in statistics after studying at Imperial College and Edinburgh. 

## Kieron Kretschmar
[LinkedIn](https://www.linkedin.com/in/kieron-kretschmar/)

Kieron joined Cadenza Labs while completing his M.Sc. at the University of Amsterdam, where he graduated cum laude. His thesis, written in collaboration with Walter Laurito, explores representations of truthfulness in language models. It analyzes how supervised and unsupervised probes can fail to predict truthfulness under distributional shifts, highlighting failure modes and potential mitigation strategies. During his studies he has set up and organized an AI Safety reading group, and has participated in the ML4Good and Talos Fellowships. Before pivoting his career towards technical AI Safety research, he has co-founded two startups.

## Jim Chapman
[LinkedIn](https://www.linkedin.com/in/jim-chapman/)

Jim has worked in leadership roles for three non-governmental organizations, serving as board vice president, policy analyst, and executive director. He co-managed a multi-million-dollar, multi-year academic research project and currently leads a consulting firm as managing principal. After becoming concerned about AI risks, and a year of learning and upskilling, Jim is joining Cadenza Labs to leverage his 30 years of operational experience and leadership in non-profit, university, and for-profit consulting settings.

## Grégoire Dhimoïla

Grégoire's work at Cadenza Labs primarily focused on the project "Cluster-Norm for Unsupervised Probing of Knowledge." His main contribution was developing contrast-pair clustering techniques for CCS-style methods. This research was presented at the ICML MechInterp workshop. In addition to this project, Grégoire has been investigating how structures emerge in the computational graphs of neural networks. Currently, Grégoire is pursuing a Master's degree in Mathematics and Computer Science at ENS Paris-Saclay. His academic interests are centered on mechanistic interpretability and the analysis of neural networks. 

##  Advisors

We thank our advisors for their regular guidance on our research direction and other topics:

- [Erik Jenner](https://ejenner.com), AI Safety Researcher
- [Alex Mallen](https://www.linkedin.com/in/alex-mallen-815b01176/), AI Safety Researcher

## Other Collaborators

- Clément Dumas
- Kaarel Hänni
