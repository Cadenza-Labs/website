---
slug: "/about"
title: ""
---

# Team

## Kieron Kretschmar
[LinkedIn](https://www.linkedin.com/in/kieron-kretschmar/)

Kieron joined Cadenza Labs while completing his M.Sc. at the University of Amsterdam, where he graduated cum laude. His thesis, written in collaboration with Walter Laurito, explores representations of truthfulness in language models. It analyzes how supervised and unsupervised probes can fail to predict truthfulness under distributional shifts, highlighting failure modes and potential mitigation strategies. During his studies he has set up and organized an AI Safety reading group, and has participated in the ML4Good and Talos Fellowships. Before pivoting his career towards technical AI Safety research, he has co-founded two startups.

## Sharan Maiya
[LinkedIn](https://www.linkedin.com/in/sharanmaiya?originalSubdomain=uk)

Sharan first joined Cadenza Labs to work on Cluster-Normalization for Unsupervised Probing. He is a first-year PhD student at the Language Technology Lab at the University of Cambridge, where he works on interpretability and evals. Additionally, he is a MATS scholar under Evan Hubinger. Sharan has a background in statistics after studying at Imperial College and Edinburgh. 

## Walter Laurito
[LinkedIn](https://www.linkedin.com/in/walter-laurito-951565144/)

Walter was in the MATS Winter 2023 Cohort under the mentorship of John Wentworth. Walter is a doctoral researcher at [FZI](https://www.fzi.de/en) and PhD candidate at [KIT](https://www.kit.edu/english/index.php). As part of [ASET](https://www.linkedin.com/posts/), he implemented benchmarks for the UK AI Security Institute and supervised others in their implementation. Before starting his PhD in ML, Walter was working as software engineer for a couple of years after graduating in CS. For Cadenza Labs, he splits his time between being a team lead and research.


##  Advisors

We thank our advisors for their regular guidance on our research direction and other topics:

- [Erik Jenner](https://ejenner.com), AI Safety Researcher
- [Alex Mallen](https://www.linkedin.com/in/alex-mallen-815b01176/), AI Safety Researcher

## Other Collaborators

- Clément Dumas
- Kaarel Hänni
- Grégoire Dhimoïla
